"use strict";(self.webpackChunk_cumulus_website=self.webpackChunk_cumulus_website||[]).push([[66622],{15680:(e,r,a)=>{a.d(r,{xA:()=>u,yg:()=>g});var n=a(296540);function t(e,r,a){return r in e?Object.defineProperty(e,r,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[r]=a,e}function i(e,r){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter(function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable})),a.push.apply(a,n)}return a}function o(e){for(var r=1;r<arguments.length;r++){var a=null!=arguments[r]?arguments[r]:{};r%2?i(Object(a),!0).forEach(function(r){t(e,r,a[r])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach(function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(a,r))})}return e}function l(e,r){if(null==e)return{};var a,n,t=function(e,r){if(null==e)return{};var a,n,t={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],r.indexOf(a)>=0||(t[a]=e[a]);return t}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],r.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var c=n.createContext({}),s=function(e){var r=n.useContext(c),a=r;return e&&(a="function"==typeof e?e(r):o(o({},r),e)),a},u=function(e){var r=s(e.components);return n.createElement(c.Provider,{value:r},e.children)},d="mdxType",h={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},p=n.forwardRef(function(e,r){var a=e.components,t=e.mdxType,i=e.originalType,c=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=s(a),p=t,g=d["".concat(c,".").concat(p)]||d[p]||h[p]||i;return a?n.createElement(g,o(o({ref:r},u),{},{components:a})):n.createElement(g,o({ref:r},u))});function g(e,r){var a=arguments,t=r&&r.mdxType;if("string"==typeof e||t){var i=a.length,o=new Array(i);o[0]=p;var l={};for(var c in r)hasOwnProperty.call(r,c)&&(l[c]=r[c]);l.originalType=e,l[d]="string"==typeof e?e:t,o[1]=l;for(var s=2;s<i;s++)o[s]=a[s];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},635662:(e,r,a)=>{a.r(r),a.d(r,{assets:()=>u,contentTitle:()=>c,default:()=>g,frontMatter:()=>l,metadata:()=>s,toc:()=>d});var n=a(58168),t=a(198587),i=(a(296540),a(15680)),o=["components"],l={id:"record_archival",title:"Database Record Archival",hide_title:!1},c=void 0,s={unversionedId:"features/record_archival",id:"features/record_archival",title:"Database Record Archival",description:"This documentation explains the database record archival and associated functionality.",source:"@site/../docs/features/record_archival.md",sourceDirName:"features",slug:"/features/record_archival",permalink:"/cumulus/docs/next/features/record_archival",draft:!1,tags:[],version:"current",lastUpdatedBy:"etcart",lastUpdatedAt:1759278610,formattedLastUpdatedAt:"Oct 1, 2025",frontMatter:{id:"record_archival",title:"Database Record Archival",hide_title:!1},sidebar:"docs",previous:{title:"Cumulus Change Granule Collections",permalink:"/cumulus/docs/next/features/change_granule_collection"},next:{title:"Troubleshooting",permalink:"/cumulus/docs/next/category/troubleshooting"}},u={},d=[{value:"Database Record Archive Column",id:"database-record-archive-column",level:2},{value:"Optimized Queries",id:"optimized-queries",level:2},{value:"Performance Parameters of Archival",id:"performance-parameters-of-archival",level:2},{value:"Archival Cron",id:"archival-cron",level:2},{value:"Configuration",id:"configuration",level:3},{value:"archive_records_config.schedule_expression",id:"archive_records_configschedule_expression",level:4},{value:"archive_records_config.update_limit",id:"archive_records_configupdate_limit",level:4},{value:"archive_records_config.batch_size",id:"archive_records_configbatch_size",level:4},{value:"archive_records_config.expiration_days",id:"archive_records_configexpiration_days",level:4},{value:"archive_records_config.deploy_rule",id:"archive_records_configdeploy_rule",level:4}],h={toc:d},p="wrapper";function g(e){var r=e.components,a=(0,t.A)(e,o);return(0,i.yg)(p,(0,n.A)({},h,a,{components:r,mdxType:"MDXLayout"}),(0,i.yg)("p",null,"This documentation explains the database record archival and associated functionality."),(0,i.yg)("h2",{id:"database-record-archive-column"},"Database Record Archive Column"),(0,i.yg)("p",null,'The cumulus database tables "granules" and "executions" contain a field "archived" which is part of query structure to optimize database search.'),(0,i.yg)("p",null,"A granule or execution will by default be ",(0,i.yg)("inlineCode",{parentName:"p"},"archived=false"),", but once old enough (age set by the DAAC) will be flagged with ",(0,i.yg)("inlineCode",{parentName:"p"},"archived=true"),"."),(0,i.yg)("p",null,"This makes no material difference to the content or state of the record, but does allow a granule or execution search query to access un-archived records more rapidly and at lower cost by eliminating from consideration a majority of records."),(0,i.yg)("h2",{id:"optimized-queries"},"Optimized Queries"),(0,i.yg)("p",null,"Queries can be lodged against the api incorporating this column just like any other db record column. For example, a request to list granules (non-archived) might call the cumulus api-client thusly:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-js"},"const unArchivedGranules = await listGranules({\n    prefix: 'my_prefix',\n    query: {\n        collectionId: 'COLLECTION1',\n        archived: false,\n        limit: 20,\n        sort_key: ['-updated_at']\n    }\n})\n")),(0,i.yg)("p",null,"This query would ask for the most recent 20 granules from the collection 'COLLECTION1' ",(0,i.yg)("em",{parentName:"p"},"which are not archived"),"."),(0,i.yg)("p",null,"The key reason to do this is performance, a search with ",(0,i.yg)("inlineCode",{parentName:"p"},"archived: false")," will be more performant in cases where records have been archived and therefore removed from these query results."),(0,i.yg)("h2",{id:"performance-parameters-of-archival"},"Performance Parameters of Archival"),(0,i.yg)("p",null,"In testing archived queries against substantially large databases there is one key exception to where these searches against un-archived records are more performant, and that is when querying records right up against the temporal border between archived and un-archived records. the inversely sorted search of the above example:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-js"},"const unArchivedGranules = await listGranules({\n    prefix: 'my_prefix',\n    query: {\n        collectionId: 'COLLECTION1',\n        archived: false,\n        limit: 20,\n        sort_key: ['updated_at']\n    }\n})\n")),(0,i.yg)("p",null,"will be similar performance or even marginally worse than searching without setting archived: false."),(0,i.yg)("h2",{id:"archival-cron"},"Archival Cron"),(0,i.yg)("p",null,"There is a pair of api endpoints which are run on a schedule, and archive a batch of either granules or executions older than a certain age. These will run asynchronously and automatically in the background of ingest and should be run at a cadence to keep up with ingest. A slower, more conservative cadence will still be functional, and improve performance, but will fail over time to keep up with archiving ",(0,i.yg)("em",{parentName:"p"},"all")," old records."),(0,i.yg)("h3",{id:"configuration"},"Configuration"),(0,i.yg)("p",null,"Configuration for this functionality is set in the cumulus tf-module, and is structured as follows:"),(0,i.yg)("h4",{id:"archive_records_configschedule_expression"},"archive_records_config.schedule_expression"),(0,i.yg)("p",null,"Cron schedule for running the task, using a Cloudwatch cron expression."),(0,i.yg)("p",null,"Default Value is ",(0,i.yg)("inlineCode",{parentName:"p"},'"cron(0 4 * * ? *)"')),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-tf"},'archive_records_config = {\n  schedule_expression = "cron(0 * * * ? *)" # execute every hour\n}\n')),(0,i.yg)("p",null,"This configuration would set it to run every hour instead"),(0,i.yg)("h4",{id:"archive_records_configupdate_limit"},"archive_records_config.update_limit"),(0,i.yg)("p",null,"How many executions and granules to archive in one run of the task function.  This will archive up to <archive_update_limit> granules ",(0,i.yg)("em",{parentName:"p"},"and")," up to <archive_update_limit> executions. This task function will run in ecs, avoiding uncertainty about time limitations"),(0,i.yg)("p",null,"Default value is 10000."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-tf"},"archive_records_config = {\n  update_limit = 200000, # update 200000 at a time\n}\n")),(0,i.yg)("h4",{id:"archive_records_configbatch_size"},"archive_records_config.batch_size"),(0,i.yg)("p",null,"Processing batch size, size of individual update calls to Postgres"),(0,i.yg)("p",null,"Default value is 1000."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-tf"},"archive_records_config = {\n  batch_size = 1000, # update in batches of 1000\n}\n")),(0,i.yg)("h4",{id:"archive_records_configexpiration_days"},"archive_records_config.expiration_days"),(0,i.yg)("p",null,"How old a record should be in days before it is archived."),(0,i.yg)("p",null,"Default value is 365"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-tf"},"archive_records_config = {\n  expiration_days = 30, # archive records more than 30 days old\n}\n")),(0,i.yg)("h4",{id:"archive_records_configdeploy_rule"},"archive_records_config.deploy_rule"),(0,i.yg)("p",null,"Should the eventBridge rule be deployed. setting this to false will cause the archive not to be deployed at all. The api endpoint will still exist and can be called directly, but will not happen automatically."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-tf"},"archive_records_config = {\n  deploy_rule = false, # don't deploy the eventbridge rule\n}\n")))}g.isMDXComponent=!0}}]);