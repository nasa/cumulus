"use strict";(self.webpackChunk_cumulus_website=self.webpackChunk_cumulus_website||[]).push([[42397],{15680(e,n,a){a.d(n,{xA:()=>g,yg:()=>d});var t=a(296540);function i(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function r(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),a.push.apply(a,t)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?r(Object(a),!0).forEach(function(n){i(e,n,a[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))})}return e}function s(e,n){if(null==e)return{};var a,t,i=function(e,n){if(null==e)return{};var a,t,i={},r=Object.keys(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||(i[a]=e[a]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var o=t.createContext({}),p=function(e){var n=t.useContext(o),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},g=function(e){var n=p(e.components);return t.createElement(o.Provider,{value:n},e.children)},h={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},u=t.forwardRef(function(e,n){var a=e.components,i=e.mdxType,r=e.originalType,o=e.parentName,g=s(e,["components","mdxType","originalType","parentName"]),u=p(a),d=i,c=u["".concat(o,".").concat(d)]||u[d]||h[d]||r;return a?t.createElement(c,l(l({ref:n},g),{},{components:a})):t.createElement(c,l({ref:n},g))});function d(e,n){var a=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=a.length,l=new Array(r);l[0]=u;var s={};for(var o in n)hasOwnProperty.call(n,o)&&(s[o]=n[o]);s.originalType=e,s.mdxType="string"==typeof e?e:i,l[1]=s;for(var p=2;p<r;p++)l[p]=a[p];return t.createElement.apply(null,l)}return t.createElement.apply(null,a)}u.displayName="MDXCreateElement"},887274(e,n,a){a.r(n),a.d(n,{assets:()=>g,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>p,toc:()=>h});var t=a(58168),i=a(198587),r=(a(296540),a(15680)),l=["components"],s={id:"granule-id-hashing-approach",title:"Unique Granule ID Generation Strategy"},o=void 0,p={unversionedId:"features/granule-id-hashing-approach",id:"features/granule-id-hashing-approach",title:"Unique Granule ID Generation Strategy",description:"Unique Granule ID Generation Strategy",source:"@site/../docs/features/granule-id-hashing-approach.md",sourceDirName:"features",slug:"/features/granule-id-hashing-approach",permalink:"/cumulus/docs/next/features/granule-id-hashing-approach",draft:!1,tags:[],version:"current",lastUpdatedBy:"Jonathan Kovarik",lastUpdatedAt:1757086072,formattedLastUpdatedAt:"Sep 5, 2025",frontMatter:{id:"granule-id-hashing-approach",title:"Unique Granule ID Generation Strategy"}},g={},h=[{value:"Unique Granule ID Generation Strategy",id:"unique-granule-id-generation-strategy",level:2},{value:"Hash Generation",id:"hash-generation",level:2},{value:"Core Task Component Hash Value Configuration",id:"core-task-component-hash-value-configuration",level:3},{value:"HashLength",id:"hashlength",level:3},{value:"IncludeTimestampHashKey",id:"includetimestamphashkey",level:3},{value:"Benefits",id:"benefits",level:2},{value:"Collision Risk Analysis",id:"collision-risk-analysis",level:2},{value:"Reference Implementations",id:"reference-implementations",level:2},{value:"Node.js",id:"nodejs",level:3},{value:"python",id:"python",level:3},{value:"java",id:"java",level:3}],u={toc:h};function d(e){var n=e.components,a=(0,i.A)(e,l);return(0,r.yg)("wrapper",(0,t.A)({},u,a,{components:n,mdxType:"MDXLayout"}),(0,r.yg)("h2",{id:"unique-granule-id-generation-strategy"},"Unique Granule ID Generation Strategy"),(0,r.yg)("p",null,"To ensure granule uniqueness within the system, especially in scenarios where a producer might ingest a granule with the same ",(0,r.yg)("inlineCode",{parentName:"p"},"granuleId")," multiple times (e.g., retries or reprocessing), a unique ID is generated using an entropy expansion strategy."),(0,r.yg)("p",null,"The format for the unique granule ID is: ",(0,r.yg)("inlineCode",{parentName:"p"},"<producerId>_<hash>")),(0,r.yg)("p",null,"This approach makes the ID human-interpretable, as users can infer the original producer ID directly from the generated ID, while the appended hash guarantees uniqueness."),(0,r.yg)("hr",null),(0,r.yg)("h2",{id:"hash-generation"},"Hash Generation"),(0,r.yg)("p",null,"The appended hash is a truncated, Base64URL-encoded MD5 hash. The length of this hash can be configured depending on the expected number of duplicate ",(0,r.yg)("inlineCode",{parentName:"p"},"granuleId")," ingests."),(0,r.yg)("p",null,"The hash input is the collectionId, optionally combined with a high-resolution timestamp, concatenated with an underscore."),(0,r.yg)("p",null,"The hashing process follows these steps:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},"Construct the hash input string as:"),(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"<collectionId>_<timestamp>")," if includeTimestampHashKey=true"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"<collectionId>")," if includeTimestampHashKey=false. (default)"))),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},"Compute the MD5 digest of the UTF-8 encoded string.")),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},"Encode the MD5 digest using Base64URL (no padding).")),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},"Slice the resulting string to the configured hashLength."),(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre"},"***Important***:\n")),(0,r.yg)("p",{parentName:"li"},"By ",(0,r.yg)("em",{parentName:"p"},"default")," the included generation code in @cumulus/ingest/granule.generateUniqueGranuleId used in both ",(0,r.yg)("inlineCode",{parentName:"p"},"ParsePDR")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"AddUniqueGranuleId")," tasks sets configuration of the computed hash to not include ",(0,r.yg)("inlineCode",{parentName:"p"},"timestamp")," and instead only compute a hash based on the ",(0,r.yg)("inlineCode",{parentName:"p"},"collectionId")," to avoid duplicate re-ingest scenarios for ingest flows that utilize filenames for granule discovery instead of triggering workflows via messages/queues, as it's believed this would be the more frequently encountered scenario versus same-collection duplicative ID scenarios."))),(0,r.yg)("h3",{id:"core-task-component-hash-value-configuration"},"Core Task Component Hash Value Configuration"),(0,r.yg)("p",null,"For the tasks that use this approach (",(0,r.yg)("inlineCode",{parentName:"p"},"AddUniqueGranuleId")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"ParsePdr"),") the values for ",(0,r.yg)("inlineCode",{parentName:"p"},"hashLength")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"includeTimestampHashKey")," can be\nconfigured in the task config via ",(0,r.yg)("inlineCode",{parentName:"p"},"collection"),", ",(0,r.yg)("inlineCode",{parentName:"p"},"rule")," or any other message/workflow configuration hooks."),(0,r.yg)("h3",{id:"hashlength"},"HashLength"),(0,r.yg)("p",null,"Hashlength will be the desired length of the hash that is being appended to the uniquified granuleId. For example if ",(0,r.yg)("inlineCode",{parentName:"p"},"hashLength")," is set to ",(0,r.yg)("inlineCode",{parentName:"p"},"3"),", when the\n",(0,r.yg)("inlineCode",{parentName:"p"},"generateUniqueGranuleId")," function is ran, the returned ",(0,r.yg)("inlineCode",{parentName:"p"},"granuleId")," would be ",(0,r.yg)("inlineCode",{parentName:"p"},"<id>_<random string value of length 3>")," (if the ",(0,r.yg)("inlineCode",{parentName:"p"},"id"),", the original ",(0,r.yg)("inlineCode",{parentName:"p"},"producerGranuleId"),", is ",(0,r.yg)("inlineCode",{parentName:"p"},"MOD.GRANULE"),", a possible\noutput could be ",(0,r.yg)("inlineCode",{parentName:"p"},"MOD.GRANULE_a1q"),", with the uniquified hash value being the ",(0,r.yg)("inlineCode",{parentName:"p"},"a1q")," which has a length of 3). By default, when this value is not set in the task config, it will be ",(0,r.yg)("inlineCode",{parentName:"p"},"8"),"."),(0,r.yg)("h3",{id:"includetimestamphashkey"},"IncludeTimestampHashKey"),(0,r.yg)("p",null,"IncludeTimestampHashKey is a boolean that controls how the unique hash is generated in the ",(0,r.yg)("inlineCode",{parentName:"p"},"generateUniqueGranuleId")," function:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"If ",(0,r.yg)("inlineCode",{parentName:"p"},"false"),": The hash is based only on ",(0,r.yg)("inlineCode",{parentName:"p"},"collectionId"),". This means:"),(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},"Duplicates within the same collection will collide, as their hash will be identical."),(0,r.yg)("li",{parentName:"ul"},"Duplicates across different collections are supported."))),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"If ",(0,r.yg)("inlineCode",{parentName:"p"},"true"),": The hash includes ",(0,r.yg)("inlineCode",{parentName:"p"},"collectionId")," and a timestamp, ensuring:"),(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},"All granules are uniquified, even duplicates in the same collection."),(0,r.yg)("li",{parentName:"ul"},"Collision risk is extremely low (less than 0.1%).")))),(0,r.yg)("hr",null),(0,r.yg)("h2",{id:"benefits"},"Benefits"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Idempotency on Retry/Producer ID re-issue"),": The inclusion of a high-resolution timestamp ensures that if an ingest fails and is retried or a granule is re-generated with the same producer identifier, a new unique hash will be generated, preventing collisions and allowing granule versioning."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Flexibility if same-collection versioning is not desired"),":  GranuleIds can be distinct across collections while still allowing same-collection collisions."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Portability"),": The use of MD5 and Base64URL is highly portable across languages and platforms, with standard library support in most environments."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Human Interpretability"),": Users can easily identify the original producer ID from the unique granule ID."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("strong",{parentName:"li"},"Low Complexity"),": The implementation is straightforward and relies on well-understood, common libraries.")),(0,r.yg)("hr",null),(0,r.yg)("h2",{id:"collision-risk-analysis"},"Collision Risk Analysis"),(0,r.yg)("p",null,"The primary risk is a hash collision for ingests with the same producer ID. The probability of a collision is governed by the birthday problem. (For a detailed explanation, see ",(0,r.yg)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Birthday_problem"},"Birthday problem on Wikipedia"),"."),(0,r.yg)("p",null,"Based on internal feature analysis, the collision risk for 10,000 ingests of granules with the same producer ID ",(0,r.yg)("em",{parentName:"p"},"when using timestamp in the hash value")," is as follows:"),(0,r.yg)("table",null,(0,r.yg)("thead",{parentName:"table"},(0,r.yg)("tr",{parentName:"thead"},(0,r.yg)("th",{parentName:"tr",align:"left"},"Hash Length (chars)"),(0,r.yg)("th",{parentName:"tr",align:"left"},"Distinct Values (6 bits per char)"),(0,r.yg)("th",{parentName:"tr",align:"left"},"% Collision Risk for 10K same-ID ingests"))),(0,r.yg)("tbody",{parentName:"table"},(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:"left"},"6"),(0,r.yg)("td",{parentName:"tr",align:"left"},"$2^{36}$"),(0,r.yg)("td",{parentName:"tr",align:"left"},"0.07273311278%")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:"left"},"7"),(0,r.yg)("td",{parentName:"tr",align:"left"},"$2^{42}$"),(0,r.yg)("td",{parentName:"tr",align:"left"},"0.001136861915%")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:"left"},"8"),(0,r.yg)("td",{parentName:"tr",align:"left"},"$2^{48}$"),(0,r.yg)("td",{parentName:"tr",align:"left"},"0.00001776356682%")),(0,r.yg)("tr",{parentName:"tbody"},(0,r.yg)("td",{parentName:"tr",align:"left"},"9"),(0,r.yg)("td",{parentName:"tr",align:"left"},"$2^{54}$"),(0,r.yg)("td",{parentName:"tr",align:"left"},"0.0000002775557562%")))),(0,r.yg)("p",null,"A default ",(0,r.yg)("strong",{parentName:"p"},"hash length of 8 characters")," provides a low risk of collision for the expected scale, and configurability in that value should allow for any unexpected scenarios to be addressed."),(0,r.yg)("h2",{id:"reference-implementations"},"Reference Implementations"),(0,r.yg)("p",null,"The following are reference implementations of the proposed function in Node.js, Python, and Java.   Please note the following caveats:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"These are for reference/demonstration of multi-language compatibility, be sure to validate / ",(0,r.yg)("em",{parentName:"li"},"use at your own risk")),(0,r.yg)("li",{parentName:"ul"},"Timestamps will not be exact across implementations and/or systems")),(0,r.yg)("h3",{id:"nodejs"},"Node.js"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-javascript"},"import crypto from 'node:crypto';\n\n/**\n * Generates a unique granule ID by appending a truncated MD5 hash of values from\n * a producer provided granule object\n *\n * @param id - An ID associated with the object to be hashed.  Likely the ID\n * assigned by the granule producer\n * @param collectionId - The api collection ID (name___version) associated with the granule\n * @param hashLength - The length of the hash to append to the granuleId.\n * @param includeTimestampHashKey - Boolean value for whether hash string should contain timestamp\n * @returns - A unique granule ID in the format: granuleId_hash.\n */\nexport function generateUniqueGranuleId(\n  id: string, collectionId: string, hashLength: number, includeTimestampHashKey?: boolean\n): string {\n  // use MD5 to generate truncated hash of granule object\n  const hashStringWithTimestamp = `${collectionId}_${process.hrtime.bigint().toString()}`;\n  const hashStringWithoutTimestamp = `${collectionId}`;\n  const hashString = includeTimestampHashKey ? hashStringWithTimestamp : hashStringWithoutTimestamp;\n  const hashBuffer = crypto.createHash('md5').update(hashString).digest();\n  return `${id}_${hashBuffer.toString('base64url').replace(/_/g, '').slice(0, hashLength)}`;\n}\n")),(0,r.yg)("h3",{id:"python"},"python"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'import hashlib\nimport base64\nimport time\n\ndef unique_granule_id(\n    id: str,\n    collection_id: str,\n    hash_length: int,\n    include_timestamp_hash_key: bool = False\n) -> str:\n    if include_timestamp_hash_key:\n        hash_string = f"{collection_id}_{time.time_ns()}"\n    else:\n        hash_string = collection_id\n\n    md5_digest = hashlib.md5(hash_string.encode("utf-8")).digest()\n    # urlsafe + strip \'=\' padding to match Node\'s unpadded base64url\n    base64url = base64.urlsafe_b64encode(md5_digest).decode("utf-8").rstrip("=")\n    cleaned = base64url.replace("_", "")\n    hash_part = cleaned[:hash_length]\n\n    return f"{id}_{hash_part}"\n')),(0,r.yg)("h3",{id:"java"},"java"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-java"},'import java.nio.charset.StandardCharsets;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Base64;\n\npublic class UniqueGranuleIdGenerator {\n  public static String uniqueGranuleId(\n      String id,\n      String collectionId,\n      int hashLength,\n      boolean includeTimestampHashKey\n  ) {\n    try {\n      final String hashString = includeTimestampHashKey\n          ? collectionId + "_" + System.nanoTime()\n          : collectionId;\n\n      final MessageDigest md5 = MessageDigest.getInstance("MD5");\n      final byte[] digest = md5.digest(hashString.getBytes(StandardCharsets.UTF_8));\n\n      // URL-safe Base64 without \'=\' padding, same alphabet as Node\'s \'base64url\'\n      final String base64url = Base64.getUrlEncoder().withoutPadding().encodeToString(digest);\n      final String cleaned = base64url.replace("_", "");\n      final String hashPart = cleaned.substring(0, Math.min(hashLength, cleaned.length()));\n\n      return id + "_" + hashPart;\n    } catch (NoSuchAlgorithmException e) {\n      throw new RuntimeException("MD5 algorithm not available", e);\n    }\n  }\n}\n')))}d.isMDXComponent=!0}}]);