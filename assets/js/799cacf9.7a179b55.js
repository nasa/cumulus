"use strict";(self.webpackChunk_cumulus_website=self.webpackChunk_cumulus_website||[]).push([[1536],{15680(e,n,a){a.d(n,{xA:()=>d,yg:()=>g});var t=a(296540);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function o(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),a.push.apply(a,t)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?o(Object(a),!0).forEach(function(n){r(e,n,a[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))})}return e}function i(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var u=t.createContext({}),s=function(e){var n=t.useContext(u),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},d=function(e){var n=s(e.components);return t.createElement(u.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},c=t.forwardRef(function(e,n){var a=e.components,r=e.mdxType,o=e.originalType,u=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),c=s(a),g=r,m=c["".concat(u,".").concat(g)]||c[g]||p[g]||o;return a?t.createElement(m,l(l({ref:n},d),{},{components:a})):t.createElement(m,l({ref:n},d))});function g(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=a.length,l=new Array(o);l[0]=c;var i={};for(var u in n)hasOwnProperty.call(n,u)&&(i[u]=n[u]);i.originalType=e,i.mdxType="string"==typeof e?e:r,l[1]=i;for(var s=2;s<o;s++)l[s]=a[s];return t.createElement.apply(null,l)}return t.createElement.apply(null,a)}c.displayName="MDXCreateElement"},93917(e,n,a){a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>u,default:()=>g,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var t=a(58168),r=a(198587),o=(a(296540),a(15680)),l=["components"],i={id:"update-granules-to-include-producer_granule_id",title:"Update granules to include producer_granule_id",hide_title:!1},u=void 0,s={unversionedId:"upgrade-notes/update-granules-to-include-producer_granule_id",id:"upgrade-notes/update-granules-to-include-producer_granule_id",title:"Update granules to include producer_granule_id",description:"Background",source:"@site/../docs/upgrade-notes/update-granules-to-include-producer_granule_id.md",sourceDirName:"upgrade-notes",slug:"/upgrade-notes/update-granules-to-include-producer_granule_id",permalink:"/cumulus/docs/next/upgrade-notes/update-granules-to-include-producer_granule_id",draft:!1,tags:[],version:"current",lastUpdatedBy:"Paul Pilone",lastUpdatedAt:1769094662,formattedLastUpdatedAt:"Jan 22, 2026",frontMatter:{id:"update-granules-to-include-producer_granule_id",title:"Update granules to include producer_granule_id",hide_title:!1},sidebar:"docs",previous:{title:"Add and Index Archived Column",permalink:"/cumulus/docs/next/upgrade-notes/archived_column_indexing"},next:{title:"External Contributions",permalink:"/cumulus/docs/next/category/external-contributions"}},d={},p=[{value:"Background",id:"background",level:2},{value:"Prerequisite",id:"prerequisite",level:2},{value:"Apply the Changes in Production Environment",id:"apply-the-changes-in-production-environment",level:2},{value:"Tools Used",id:"tools-used",level:2},{value:"Upgrade Steps",id:"upgrade-steps",level:2}],c={toc:p};function g(e){var n=e.components,a=(0,r.A)(e,l);return(0,o.yg)("wrapper",(0,t.A)({},c,a,{components:n,mdxType:"MDXLayout"}),(0,o.yg)("h2",{id:"background"},"Background"),(0,o.yg)("p",null,"As part of the work for ",(0,o.yg)("a",{parentName:"p",href:"https://bugs.earthdata.nasa.gov/browse/CUMULUS-4058"},"CUMULUS-4058 Handle Granules with Identical producerGranuleId in Different\nCollections"),", we are adding a\nproducer_granule_id column to the granules table."),(0,o.yg)("p",null,"The following updates are included:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Check for duplicate granule_id values"),(0,o.yg)("li",{parentName:"ul"},"Add a new producer_granule_id column to the granules table"),(0,o.yg)("li",{parentName:"ul"},"Populate the producer_granule_id column in batches with values from the granule_id column"),(0,o.yg)("li",{parentName:"ul"},"Make the producer_granule_id column NOT NULL and create an index on it"),(0,o.yg)("li",{parentName:"ul"},"Vacuum the granules table")),(0,o.yg)("p",null,"The updates will be automatically created as part of the bootstrap lambda function on deployment of the data-persistence module."),(0,o.yg)("p",null,(0,o.yg)("em",{parentName:"p"},"In cases where the column and index are already applied, the updates will have no effect.")),(0,o.yg)("h2",{id:"prerequisite"},"Prerequisite"),(0,o.yg)("p",null,"Verify that there are no duplicate granule_id values in the granules table.\nIf any are found, identify and remove the redundant records."),(0,o.yg)("p",null,"Previous Cumulus releases did not support ingesting the same granule_id across different collections.\nTherefore, in theory, there should be no duplicate granule_id values in the granules table. However,\nthe current database schema does allow duplicates by design, as it enforces uniqueness only on the\ncombination of granule_id and collection_cumulus_id through a composite unique index."),(0,o.yg)("p",null,"To identify any duplicate granule_id values, run the following query:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-sql"},"SELECT granule_id, COUNT(*) AS count\nFROM granules\nGROUP BY granule_id\nHAVING COUNT(*) > 1\nORDER BY count DESC;\n")),(0,o.yg)("admonition",{type:"note"},(0,o.yg)("p",{parentName:"admonition"},"The migration script will abort if there are duplicate granule_id values in the granules table.")),(0,o.yg)("h2",{id:"apply-the-changes-in-production-environment"},"Apply the Changes in Production Environment"),(0,o.yg)("p",null,"For large databases (e.g., when the ",(0,o.yg)("inlineCode",{parentName:"p"},"granules")," table contains more than 100,000 rows), updates must\nbe applied manually, as the commands can take a significant amount of time. Since ",(0,o.yg)("inlineCode",{parentName:"p"},"ALTER TABLE"),"\ncommands require an ",(0,o.yg)("strong",{parentName:"p"},"exclusive lock")," on the table, and populating the new column is time-consuming,\nit is recommended to ",(0,o.yg)("strong",{parentName:"p"},"quiesce all database activity")," during this process. This means pausing\nIngest, Archive, and other Cumulus functions before and during the execution of these commands."),(0,o.yg)("p",null,"The table below, from the LP DAAC SNAPSHOT database running on Aurora Serverless v2 with\nPostgreSQL 17.4, shows the table sizes before and after the migration commands, along with their\nexecution times. The commands were run using 32 ACUs, and table sizes were measured using the\nfollowing query:"),(0,o.yg)("pre",null,(0,o.yg)("code",{parentName:"pre",className:"language-sql"},"SELECT pg_size_pretty(pg_total_relation_size('granules'));\n")),(0,o.yg)("table",null,(0,o.yg)("thead",{parentName:"table"},(0,o.yg)("tr",{parentName:"thead"},(0,o.yg)("th",{parentName:"tr",align:null},"Table Name"),(0,o.yg)("th",{parentName:"tr",align:null},"Original Table Size"),(0,o.yg)("th",{parentName:"tr",align:null},"New Table Size"),(0,o.yg)("th",{parentName:"tr",align:null},"Number of Rows"),(0,o.yg)("th",{parentName:"tr",align:null},"Migration Time"))),(0,o.yg)("tbody",{parentName:"table"},(0,o.yg)("tr",{parentName:"tbody"},(0,o.yg)("td",{parentName:"tr",align:null},"granules"),(0,o.yg)("td",{parentName:"tr",align:null},"230 GB"),(0,o.yg)("td",{parentName:"tr",align:null},"241 GB"),(0,o.yg)("td",{parentName:"tr",align:null},"163 M"),(0,o.yg)("td",{parentName:"tr",align:null},"10 hours 40 minutes (1 worker)",(0,o.yg)("br",null),"3 hours 40 minutes (5 workers)",(0,o.yg)("br",null),"2 hours 30 minutes (10 workers)")))),(0,o.yg)("h2",{id:"tools-used"},"Tools Used"),(0,o.yg)("p",null,"Since the update commands can take a few hours to run based on table size and IO throughput, it is recommended that the commands are run in an EC2 instance\nin the AWS environment in a tmux or screen session. This will minimize the number of network hops and potential disconnects between the database client\nand the database. Additionally, this will allow operators applying the patch to check on progress periodically and not worry about credential expiration or\nother issues that would result in the client being killed."),(0,o.yg)("h2",{id:"upgrade-steps"},"Upgrade Steps"),(0,o.yg)("ol",null,(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Quiesce ingest"),(0,o.yg)("p",{parentName:"li"},"Stop all ingest operations in Cumulus Core according to your operational procedures. You should validate\nthat it appears there are no active queries that appear to be inserting granules/files into the database\nas a secondary method of evaluating the database system state:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-text"},"select pid, query, state, wait_event_type, wait_event from pg_stat_activity where state = 'active';\n")),(0,o.yg)("p",{parentName:"li"},"If query rows are returned with a ",(0,o.yg)("inlineCode",{parentName:"p"},"query")," value that involves the tables, make sure ingest is halted\nand no other granule-update activity is running on the system."),(0,o.yg)("admonition",{parentName:"li",type:"note"},(0,o.yg)("p",{parentName:"admonition"},"In rare instances if there are hung queries that are unable to resolve, it may be necessary to\nmanually use psql ",(0,o.yg)("a",{parentName:"p",href:"https://www.postgresql.org/docs/17/functions-admin.html#FUNCTIONS-ADMIN-SIGNAL"},"Server Signaling\nFunctions"),"\n",(0,o.yg)("inlineCode",{parentName:"p"},"pg_cancel_backend")," and/or\n",(0,o.yg)("inlineCode",{parentName:"p"},"pg_terminate_backend")," to end the queries."))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Login into EC2 instance with database access."),(0,o.yg)("p",{parentName:"li"},"From AWS console: Go to EC2, pick a ",(0,o.yg)("inlineCode",{parentName:"p"},"<prefix>-CumulusECSCluster")," instance, click Connect, click Session Manager\nand click the Connect button."),(0,o.yg)("p",{parentName:"li"},"From AWS CLI: aws ssm start-session --target ",(0,o.yg)("inlineCode",{parentName:"p"},"EC2 Instance ID"),"."),(0,o.yg)("admonition",{parentName:"li",title:"Remember to take a note on which instance you run the commands.",type:"note"})),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Install tmux, postgres client and python packages"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sh"},"sudo yum install -y tmux\nsudo dnf install -y postgresql17\nsudo dnf install -y python3 python3-pip\npip3 install --user psycopg2-binary\n")),(0,o.yg)("p",{parentName:"li"},"Once installed, a ",(0,o.yg)("inlineCode",{parentName:"p"},"tmux")," session is started with two windows. Alternatively, you can open two\nconcurrent SSM sessions to the same EC2 instance and start a separate tmux session from each."),(0,o.yg)("p",{parentName:"li"},"The primary window is used to run the migration script, while the secondary window is used\nto monitor the database. When the operator's shift ends or monitoring is no longer needed,\nthe tmux session can be detached and reattached later as needed.")),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Run Migration Script\nThe database login credentials can be retrieved from the ",(0,o.yg)("inlineCode",{parentName:"p"},"<prefix>_db_login")," secret.\nWhen the migration script is running, perform step 5 to monitor the commands."),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sh"},"curl -o /home/ssm-user/20250425134823_granules_add_producer_granule_id.py https://raw.githubusercontent.com/nasa/cumulus/master/packages/db/src/migrations/20250425134823_granules_add_producer_granule_id.py\n\ntmux new-session -s CumulusUpgrade -n add-producer_granule_id\npython3 /home/ssm-user/20250425134823_granules_add_producer_granule_id.py\n")),(0,o.yg)("admonition",{parentName:"li",type:"note"},(0,o.yg)("p",{parentName:"admonition"},(0,o.yg)("strong",{parentName:"p"},"BATCH SIZE"),": The actual number of rows updated in each batch may be less than BATCH_SIZE because\ncumulus_id values may not increase by exactly 1."),(0,o.yg)("p",{parentName:"admonition"},(0,o.yg)("strong",{parentName:"p"},"Number of parallel workers"),": This value controls how many concurrent threads process batches of\n",(0,o.yg)("inlineCode",{parentName:"p"},"producer_granule_id")," updates. Increasing it can speed up processing but may also increase the load\non the database. Adjust based on system capacity and performance needs.")),(0,o.yg)("p",{parentName:"li"},"Example output from migrating the LP DAAC SNAPSHOT database:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sh"},"$ python3 /home/ssm-user/20250425134823_granules_add_producer_granule_id.py\nEnter DB host []: cumulus-dev-rds-cluster.cluster-xxx.us-east-1.rds.amazonaws.com\nEnter DB port [5432]:\nEnter DB name []: cumulus_test_db\nEnter DB user []: cumulus_test\nEnter DB password:\nEnter BATCH SIZE for populating column [100000]:\nNumber of parallel workers [1]: 5\nBatch Update Recovery mode? (Y/N) [N]:\n[2025-08-28T12:24:19.981864] Checking for duplicate granule_id values...\n[2025-08-28T12:35:40.802003] No duplicate granule_id values found.\n[2025-08-28T12:35:40.802177] Adding column producer_granule_id if not present...\n[2025-08-28T12:35:41.279347] Column check complete.\n[2025-08-28T12:35:41.279536] Disabling autovacuum on granules table...\n[2025-08-28T12:35:41.293261] Autovacuum disabled.\n[2025-08-28T12:35:41.295678] Fetching min/max cumulus_id values (Normal mode)...\n[2025-08-28T12:35:41.336381] Populating cumulus_id range: 3 to 560391416\n[2025-08-28T12:35:41.336432] Starting parallel batch update with 5 worker(s)...\n[2025-08-28T12:35:41.355991] [Worker] Updating rows where cumulus_id BETWEEN 3 AND 100002\n[2025-08-28T12:35:41.361517] [Worker] Updating rows where cumulus_id BETWEEN 200003 AND 300002\n[2025-08-28T12:35:41.361676] [Worker] Updating rows where cumulus_id BETWEEN 100003 AND 200002\n[2025-08-28T12:35:41.361784] [Worker] Updating rows where cumulus_id BETWEEN 300003 AND 400002\n[2025-08-28T12:35:41.361893] [Worker] Updating rows where cumulus_id BETWEEN 400003 AND 500002\n[2025-08-28T12:36:12.394086] [Worker] Updated 23062 rows where cumulus_id BETWEEN 300003 AND 400002\n[2025-08-28T12:36:12.394207] [Worker] Updated 23028 rows where cumulus_id BETWEEN 200003 AND 300002\n[2025-08-28T12:36:12.410337] [Worker] Updating rows where cumulus_id BETWEEN 500003 AND 600002\n[2025-08-28T12:36:12.410914] [Worker] Updating rows where cumulus_id BETWEEN 600003 AND 700002\n[2025-08-28T12:36:12.413539] [Worker] Updated 22829 rows where cumulus_id BETWEEN 100003 AND 200002\n...\n[2025-08-28T15:31:50.150774] [Worker] Updating rows where cumulus_id BETWEEN 560100003 AND 560200002\n[2025-08-28T15:31:51.161134] [Worker] Updated 2825 rows where cumulus_id BETWEEN 560100003 AND 560200002\n[2025-08-28T15:31:51.178434] [Worker] Updating rows where cumulus_id BETWEEN 560200003 AND 560300002\n[2025-08-28T15:31:53.548197] [Worker] Updated 19121 rows where cumulus_id BETWEEN 559900003 AND 560000002\n[2025-08-28T15:31:53.564171] [Worker] Updating rows where cumulus_id BETWEEN 560300003 AND 560391416\n[2025-08-28T15:31:53.625941] [Worker] Updated 3 rows where cumulus_id BETWEEN 560300003 AND 560391416\n[2025-08-28T15:31:54.883654] [Worker] Updated 16801 rows where cumulus_id BETWEEN 560000003 AND 560100002\n[2025-08-28T15:31:57.284970] [Worker] Updated 21143 rows where cumulus_id BETWEEN 560200003 AND 560300002\n[2025-08-28T15:31:57.933015] [Worker] Updated 60548 rows where cumulus_id BETWEEN 559600003 AND 559700002\n[2025-08-28T15:31:58.171666] [Worker] Updated 59506 rows where cumulus_id BETWEEN 559500003 AND 559600002\n[2025-08-28T15:31:58.172481] Parallel batch update complete.\n[2025-08-28T15:31:58.175522] Setting producer_granule_id column to NOT NULL...\n[2025-08-28T15:35:28.853811] Column is now NOT NULL.\n[2025-08-28T15:35:28.853993] Vacuuming granules table...\n[2025-08-28T15:47:06.325941] Vacuum complete.\n[2025-08-28T15:47:06.326141] Creating index on producer_granule_id...\n[2025-08-28T15:59:29.662899] Index created.\n[2025-08-28T15:59:29.663072] Re-enabling autovacuum on granules table...\n[2025-08-28T15:59:29.711125] Autovacuum re-enabled.\n[2025-08-28T15:59:29.713473] Update completed successfully.\n")),(0,o.yg)("admonition",{parentName:"li",title:"RECOVERY_MODE",type:"note"},(0,o.yg)("p",{parentName:"admonition"},"If the migration is incomplete (e.g., the ",(0,o.yg)("inlineCode",{parentName:"p"},"producer_granule_id")," column is partially populated),\nyou can run the script in ",(0,o.yg)("strong",{parentName:"p"},"recovery mode")," to resume the migration process. The script will skip\nrecords that have already been migrated.")),(0,o.yg)("p",{parentName:"li"},"You can find the SQL commands used for the migration\n",(0,o.yg)("a",{parentName:"p",href:"https://raw.githubusercontent.com/nasa/cumulus/master/packages/db/src/migrations/20250425134823_granules_add_producer_granule_id.sql"},"here"),"\nfor your reference.")),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Monitor the Running Command"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sh"},"# From tmux CumulusUpgrade session, open another window\n<Ctrl>-b c\n\npsql -h <Endpoint for writer instance> -p <Port for database or 5432> -d <cumulus database name> -U <database admin user> -W\n\nselect pid, query, state, wait_event_type, wait_event from pg_stat_activity where state = 'active';\n"))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Verify the Updates"),(0,o.yg)("p",{parentName:"li"},"We can verify that the tables are updated successfully by checking the ",(0,o.yg)("inlineCode",{parentName:"p"},"\\d+ table")," results from psql.  The following are expected results."),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sh"},'=> \\d+ granules;\n\n          Column           |           Type           | Collation | Nullable |               Default    |           Description\n---------------------------+--------------------------+-----------+----------+--------------------------+------------------------------\nproducer_granule_id        | text                     |           | not null |                          | Producer Granule Id\n\nIndexes:\n"granules_producer_granule_id_index" btree (producer_granule_id)\n'))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Make Sure Autovacuum Is Re-Enabled"),(0,o.yg)("p",{parentName:"li"},"The output of ",(0,o.yg)("inlineCode",{parentName:"p"},"\\d+ granules")," should ",(0,o.yg)("strong",{parentName:"p"},"NOT")," have output ",(0,o.yg)("inlineCode",{parentName:"p"},"Options: autovacuum_enabled=false, toast.autovacuum_enabled=false"),".\nYou can also run the following query:"),(0,o.yg)("pre",{parentName:"li"},(0,o.yg)("code",{parentName:"pre",className:"language-sh"},"SELECT relname AS table_name, reloptions\nFROM pg_class\nWHERE relname = 'granules';\n")),(0,o.yg)("p",{parentName:"li"}," reloptions should ",(0,o.yg)("strong",{parentName:"p"},"NOT")," includes ",(0,o.yg)("inlineCode",{parentName:"p"},"autovacuum_enabled=false"))),(0,o.yg)("li",{parentName:"ol"},(0,o.yg)("p",{parentName:"li"},"Close the Session"),(0,o.yg)("p",{parentName:"li"},"Close the tmux session after the task is complete by ",(0,o.yg)("inlineCode",{parentName:"p"},"exit")," or ",(0,o.yg)("inlineCode",{parentName:"p"},"<Ctrl>-b x"),"."))))}g.isMDXComponent=!0}}]);